{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2080558,"sourceType":"datasetVersion","datasetId":1247358}],"dockerImageVersionId":30664,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-15T13:41:56.511639Z","iopub.execute_input":"2024-03-15T13:41:56.512119Z","iopub.status.idle":"2024-03-15T13:41:56.521513Z","shell.execute_reply.started":"2024-03-15T13:41:56.512075Z","shell.execute_reply":"2024-03-15T13:41:56.520543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# python基础内容教学  \npython基本数据类型：[菜鸟教程：数据类型](https://www.runoob.com/python3/python3-data-type.html)\n\n","metadata":{}},{"cell_type":"markdown","source":"# 如何使用GPT去辅助代码","metadata":{}},{"cell_type":"markdown","source":"# Kaggle 基本使用  \nkaggle 账号登录与注册  \nkaggle 学习与练习  \nkaggle 数据的下载与加载  \n","metadata":{}},{"cell_type":"markdown","source":"# Python pandas教学  \npandas基本数据结构：Series,DataFrame。  \npandas Series的常用函数，以及Series在DataFrame中的作用  \npandas DataFrame的数据结构特点，创建，数据类型的转变，索引，切片，数据操作  \npandas 读取csv文件  \npandas DataFrame数据清洗的常用函数以及用法，数据拼接  ","metadata":{}},{"cell_type":"code","source":"import pandas as pd \nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-03-15T13:41:56.523557Z","iopub.execute_input":"2024-03-15T13:41:56.524683Z","iopub.status.idle":"2024-03-15T13:41:56.537284Z","shell.execute_reply.started":"2024-03-15T13:41:56.524641Z","shell.execute_reply":"2024-03-15T13:41:56.535206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#数据加载\ndf = pd.read_csv(r\"/kaggle/input/data-science-day1-titanic/DSB_Day1_Titanic_train.csv\")\n#DataFrame的创建：分别使用字典以及数组的方式创建DataFrame\ndf_1 = pd.DataFrame({'name':['mike','julily'],'couse':['English','Chinese']})\ndf_2 = pd.DataFrame(np.array([['mike','English'],['julily','Chinese']]),columns = ['name','couse'])\nprint(df_1)\nprint(df_2)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T14:20:00.132500Z","iopub.execute_input":"2024-03-15T14:20:00.132893Z","iopub.status.idle":"2024-03-15T14:20:00.162683Z","shell.execute_reply.started":"2024-03-15T14:20:00.132865Z","shell.execute_reply":"2024-03-15T14:20:00.161466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#查看泰坦尼克号的数据\n#df.head(5)#查看前五行数据\n#df.tail(5)#查看后五行数据\n#df.sample(5)#随机查看五行数据","metadata":{"execution":{"iopub.status.busy":"2024-03-15T13:41:56.566027Z","iopub.execute_input":"2024-03-15T13:41:56.566690Z","iopub.status.idle":"2024-03-15T13:41:56.571510Z","shell.execute_reply.started":"2024-03-15T13:41:56.566651Z","shell.execute_reply":"2024-03-15T13:41:56.570440Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#获得数据结构\n#df.shape\n#获得数据的大小\n#df.size#即数据的行与列的个数相乘，包括了np.nan\n#显示所有数据的类型、索引情况、行列数、各字段数据类型、内存占用等。\n#df.info()\n#获取数据类型\n#df.dtypes\n#获取数据的列名,可转化为列表的形式\n#df.columns\n#获取数据的索引，可转化为列表的形式\n#df.index\n","metadata":{"execution":{"iopub.status.busy":"2024-03-15T13:41:56.572761Z","iopub.execute_input":"2024-03-15T13:41:56.573723Z","iopub.status.idle":"2024-03-15T13:41:56.581752Z","shell.execute_reply.started":"2024-03-15T13:41:56.573682Z","shell.execute_reply":"2024-03-15T13:41:56.580751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#描述统计信息\ndf.describe()\n#此外还包括各种统计函数与非统计计算的方法，请自行查阅","metadata":{"execution":{"iopub.status.busy":"2024-03-15T13:41:56.582966Z","iopub.execute_input":"2024-03-15T13:41:56.583859Z","iopub.status.idle":"2024-03-15T13:41:56.620900Z","shell.execute_reply.started":"2024-03-15T13:41:56.583829Z","shell.execute_reply":"2024-03-15T13:41:56.619867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# pandas 数据选取:1.如何选取特定行，特定列，筛选出满足条件的行或者列，锁定特定的元素 \n## 按行选择 df[...],按索引选择df.loc[<行表达式>, <列表达式>] 按数字选择 df.iloc[]\n## 切片选择行 df[5:10] ,筛选数据 df[表达式]","metadata":{}},{"cell_type":"code","source":"#按行选择前三行\n#df[0:3]\n#按索引选择前三行\ndf.loc[0:2,:]\n#按索引选择偶数行，并只需要PassengerId与Sex的列\ndf.loc[::2,['PassengerId','Sex']]\n#选择列的方法\ndf[['Name','PassengerId']]\n#筛选出满足年龄＞50的行\ndf[df['Age']>50]\n#筛选出年龄＞50,且存活的女性的行\ndf[(df['Age']>50) & (df['Survived']==1) & (df['Sex'] == 'female')]#逻辑运算符 & | ~\n#与loc结合\ndf.loc[df['Age']>50,['Sex','Name','Age']]","metadata":{"execution":{"iopub.status.busy":"2024-03-15T13:41:56.622727Z","iopub.execute_input":"2024-03-15T13:41:56.623129Z","iopub.status.idle":"2024-03-15T13:41:56.646933Z","shell.execute_reply.started":"2024-03-15T13:41:56.623093Z","shell.execute_reply":"2024-03-15T13:41:56.645823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pandas 数据类型转换  \n## 对所有字段指定统一类型\ndf = pd.DataFrame(data, dtype='float32')  \n## 对每个字段分别指定\ndf = pd.read_excel(data, dtype={'team': 'string', 'Q1': 'int32'}\n###  astype()是最常见也是最通用的数据类型转换方法，一般我们使用astype()操作数据转换就可以了。  ","metadata":{}},{"cell_type":"code","source":"df['Age'] = df['Age'].fillna(df['Age'].mean())#或 df['Age'].fillna(df['Age'].mean(),copy = True)\ndf['Age'].astype('int32')","metadata":{"execution":{"iopub.status.busy":"2024-03-15T13:41:56.650531Z","iopub.execute_input":"2024-03-15T13:41:56.651555Z","iopub.status.idle":"2024-03-15T13:41:56.663251Z","shell.execute_reply.started":"2024-03-15T13:41:56.651512Z","shell.execute_reply":"2024-03-15T13:41:56.662100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pandas 数据排序  \ndf.sort_index()\ndf.sort_values()\n","metadata":{}},{"cell_type":"code","source":"#修改值与loc配合\ndf.loc[df['Age']>50,['Age']] = 50\ndf[df['Age'] >=50]\n#修改列名 df.rename(columns = {})\ndf.rename(columns = {'Name':'name'})\n#修改索引 df.rename(index = {})\ndf.rename(index = {0:'a',2:'b'})\n#增加列\ndf['real_age'] = df['Age']-1\n#增加行\ndf.loc[len(df),:] = [891,1,2,'mike','male',99,1,2,3,40,'C1','S',22]\n#追加合并\ndf_6 = pd.DataFrame({'a':[1,2,3,4,5],'b':[3,3,3,3,3]})\ndf_7 = pd.DataFrame({'a':[2,3],'b':[3,3]})\npd.concat([df_6,df_7])\n#删除的两种方法，pop与反选法 pop在series中删除索引所选的值，这DataFrame中删除column，若要删除列则要用drop\ndf_6.drop([2,3],axis=0,inplace = False)\ndf_6.drop('a',axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T13:41:56.664950Z","iopub.execute_input":"2024-03-15T13:41:56.665345Z","iopub.status.idle":"2024-03-15T13:41:56.693127Z","shell.execute_reply.started":"2024-03-15T13:41:56.665317Z","shell.execute_reply":"2024-03-15T13:41:56.691937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 数据预处理常用函数  \n(1)缺失值处理：dropna(),fillna()  \n(2)重复值处理：drop_duplicates()  \n(3)检测缺失值:isnull().sum()\n[详细请看菜鸟教程](https://www.runoob.com/pandas/pandas-cleaning.html)","metadata":{}},{"cell_type":"code","source":"#删除空值\n\n#df.dropna() #一行中有一个缺失值就删除\n#df.dropna(axis='columns') # 只保留全有值的列\n#df.dropna(how='all') # 行或列全没值才删除\n#df.dropna(thresh=2) # 至少有两个空值时才删除\n#df.dropna(inplace=True) # 删除并使替换生效\n#df.fillna()\n#df.drop_duplicates()\n#df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T14:16:32.169417Z","iopub.execute_input":"2024-03-15T14:16:32.169871Z","iopub.status.idle":"2024-03-15T14:16:32.181580Z","shell.execute_reply.started":"2024-03-15T14:16:32.169840Z","shell.execute_reply":"2024-03-15T14:16:32.180244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pandas 分类聚合  \n> Pandas分组聚合\n分组聚合非常常见，我们的数据是扁平化的，没有任何分组信息。\n比如我们一周多次去一家便利店，每次会产生一条购买记录，便利店要\n想统计每个人这周的购买情况，就需要以人来进行分组，然后将每个人\n的所有金额相加  \n\n> df.groupby()方法可以按指定字段对DataFrame进行分组，生成一个\n分组器对象。","metadata":{}},{"cell_type":"code","source":"df.groupby('Age')#只对一个column进行分组\ndf.groupby(['real_age','Age']).sum()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T13:41:56.724924Z","iopub.execute_input":"2024-03-15T13:41:56.726040Z","iopub.status.idle":"2024-03-15T13:41:56.764255Z","shell.execute_reply.started":"2024-03-15T13:41:56.725990Z","shell.execute_reply":"2024-03-15T13:41:56.763117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#DataFrame 应用分组\ndf.groupby(by='Sex').size()#获取类别个数\n#df.groupby(by = 'Age').agg({'PassengerId':'sum','Fare':'mean'})\ndf.groupby(by='Sex').agg({'PassengerId':['sum','mean'],'Fare':['sum','mean']})#利用agg对一个columns数据分别进行不同的统计计算","metadata":{"execution":{"iopub.status.busy":"2024-03-15T13:41:56.766077Z","iopub.execute_input":"2024-03-15T13:41:56.766496Z","iopub.status.idle":"2024-03-15T13:41:56.788128Z","shell.execute_reply.started":"2024-03-15T13:41:56.766459Z","shell.execute_reply":"2024-03-15T13:41:56.786805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![agg能执行的操作](https://pic2.zhimg.com/v2-a0b4827a2829c7e4f9082b958f093f7d_r.jpg)","metadata":{}},{"cell_type":"markdown","source":"# Pandas 数据分箱\n> 数据分箱（data binning，也称为离散组合或数据分桶）是一种数据\n预处理技术，它将原始数据分成几个小区间，即bin（小箱子），是一\n种量子化的形式。数据分箱可以最大限度减小观察误差的影响。落入给\n定区间的原始数据值被代表该区间的值（通常是中心值）替换。然后将\n其替换为针对该区间计算的常规值。这具有平滑输入数据的作用，并且\n在小数据集的情况下还可以减少过拟合。\nPandas主要基于以两个函数实现连续数据的离散化处理。\npandas.cut：根据指定分界点对连续数据进行分箱处理。\npandas.qcut：根据指定区间数量对连续数据进行等宽分箱处理。\n所谓等宽，指的是每个区间中的数据量是相同的  \n## 数据分箱,pandas 提供了四种方法between cut qcut value_count  \n这里介绍一下cut方法  \ncut的参数如下：\n  \nx：要分箱的数组。 必须是一维的。  \nbins：标量序列：定义允许非均匀宽度的 bin 边缘。  \nlabels：指定返回的 bin 的标签。 必须与上面的 bins 参数长度相同。  \ninclude_lowest: (bool) 第一个区间是否应该是左包含的。  ","metadata":{}},{"cell_type":"code","source":"bins_1 = [0,18,40,50,70,90]\ndf['Age'] = pd.cut(df['Age'],bins = bins_1,include_lowest = True)\ndf.sample(5)\n#也可以传入labels参数将得到的分组进行分别命名\ndf['Fare'] = pd.cut(df['Fare'],bins = [1,1000,10000],labels = ['贫穷','富有'])\ndf.sample(5)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T13:42:36.927055Z","iopub.execute_input":"2024-03-15T13:42:36.927480Z","iopub.status.idle":"2024-03-15T13:42:36.958648Z","shell.execute_reply.started":"2024-03-15T13:42:36.927446Z","shell.execute_reply":"2024-03-15T13:42:36.957270Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pandas 编码  \nmap() 函数 如果需要把数据集中gender列的男替换为1，女替换为0，怎么做呢？绝对不是用for循环实现，使用Series.map()可以很容易做到，最少仅需一行代码。  \n有函数映射以及字典映射，这里介绍使用字典映射的方法  \n","metadata":{}},{"cell_type":"code","source":"df['Sex'] = df['Sex'].map({'male':1,'female':0})\ndf.sample(5)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T13:47:36.029998Z","iopub.execute_input":"2024-03-15T13:47:36.030496Z","iopub.status.idle":"2024-03-15T13:47:36.056098Z","shell.execute_reply.started":"2024-03-15T13:47:36.030458Z","shell.execute_reply":"2024-03-15T13:47:36.055013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pandas 数据拼接与合并  \n> Pandas包的merge、join、concat方法可以完成数据的合并和拼接。\n\n**merge方法主要基于两个dataframe的共同列进行合并；  \njoin方法主要基于两个dataframe的索引进行合并；  \nconcat方法是对series或dataframe进行行拼接或列拼接**[详细内容](https://zhuanlan.zhihu.com/p/113618765)  \n[可视化的图解](https://zhuanlan.zhihu.com/p/437659884)","metadata":{}},{"cell_type":"markdown","source":"# Python seaborn  \n> Seaborn 是基于 Python 且非常受欢迎的图形可视化库，在 Matplotlib 的基础上，进行了更高级的封装，使得作图更加方便快捷。即便是没有什么基础的人，也能通过极简的代码，做出具有分析价值而又十分美观的图形。  \n*散点图： sns.scatterplot(x='feature1', y='feature2', data=data)   \n折线图：  sns.lineplot(x='x_axis', y='y_axis', data=data)  \n直方图：sns.histplot(x='variable', data=data, bins=30, kde=True)  \n箱线图： sns.boxplot(x='category', y='value', data=data)\n热力图： sns.heatmap(data.corr(), annot=True, cmap='coolwarm')*  \n[详细操作](https://zhuanlan.zhihu.com/p/669896594)\n[官方文档](https://seaborn.pydata.org/tutorial/introduction.html)","metadata":{}},{"cell_type":"code","source":"#基本的环境配置\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2024-03-15T14:07:05.586016Z","iopub.execute_input":"2024-03-15T14:07:05.586498Z","iopub.status.idle":"2024-03-15T14:07:05.594490Z","shell.execute_reply.started":"2024-03-15T14:07:05.586464Z","shell.execute_reply":"2024-03-15T14:07:05.592992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()\ndf.isnull().sum()\ndf['Age'].fillna(df['Age'].mean(),inplace = True)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T14:20:53.640145Z","iopub.execute_input":"2024-03-15T14:20:53.640699Z","iopub.status.idle":"2024-03-15T14:20:53.662830Z","shell.execute_reply.started":"2024-03-15T14:20:53.640658Z","shell.execute_reply":"2024-03-15T14:20:53.661135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=2)\nsns.lineplot(x = 'Age',y = 'Survived',data = df,ax=axes[1])#绘图前记得检查是否有nan值，如果存在nan值则会无法绘制图像\nsns.boxplot(x='Pclass',y = 'Parch',data = df,ax=axes[0])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T14:27:27.651274Z","iopub.execute_input":"2024-03-15T14:27:27.651672Z","iopub.status.idle":"2024-03-15T14:27:30.355683Z","shell.execute_reply.started":"2024-03-15T14:27:27.651643Z","shell.execute_reply":"2024-03-15T14:27:30.354581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()\ndf.dropna()","metadata":{"execution":{"iopub.status.busy":"2024-03-15T14:29:21.247131Z","iopub.execute_input":"2024-03-15T14:29:21.247601Z","iopub.status.idle":"2024-03-15T14:29:21.276018Z","shell.execute_reply.started":"2024-03-15T14:29:21.247568Z","shell.execute_reply":"2024-03-15T14:29:21.274178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(data=df)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T14:30:19.496266Z","iopub.execute_input":"2024-03-15T14:30:19.496697Z","iopub.status.idle":"2024-03-15T14:30:39.008655Z","shell.execute_reply.started":"2024-03-15T14:30:19.496666Z","shell.execute_reply":"2024-03-15T14:30:39.007203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}